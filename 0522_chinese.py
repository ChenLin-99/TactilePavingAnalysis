import os
import base64
import pandas as pd
from openai import AsyncOpenAI, APIConnectionError, RateLimitError 
import httpx
import json
import asyncio 
from tqdm.asyncio import tqdm_asyncio 

# ========== å…¨å±€é…ç½® ==========
API_KEY = os.environ.get("OPENAI_API_KEY") # ä»ç¯å¢ƒå˜é‡è¯»å–APIå¯†é’¥
if not API_KEY:
    raise ValueError("è¯·è®¾ç½® OPENAI_API_KEY ç¯å¢ƒå˜é‡ã€‚ä¾‹å¦‚ï¼šexport OPENAI_API_KEY='your_api_key_here'")

client = AsyncOpenAI(api_key=API_KEY) 
print("Initializing AsyncOpenAI client...")

# è·¯å¾„é…ç½®
DATA_FOLDER = "/Users/chenlin99/Code/CHB/data" 
TEST_MODE_IMAGE_PATH = "/Users/chenlin99/Code/CHB/data/2c49fe04e349b28dc3839aa5450e0d63.jpg"
OUTPUT_FOLDER = "/Users/chenlin99/Code/CHB/results" 
BATCH_OUTPUT_FOLDER = "/Users/chenlin99/Code/CHB/results_batch" 

# æµ‹è¯•æ¨¡å¼å¼€å…³å’Œé…ç½®
TEST_MODE = False # æ§åˆ¶æ˜¯å¦å¯ç”¨æµ‹è¯•æ¨¡å¼
NUM_TEST_QUESTIONS = None # æµ‹è¯•æ¨¡å¼ä¸‹å¤„ç†çš„é—®é¢˜æ•°é‡ï¼ŒNoneè¡¨ç¤ºå¤„ç†æ‰€æœ‰é—®é¢˜
CONCURRENT_REQUEST_LIMIT = 50 # æ‰¹å¤„ç†æ—¶å¹¶å‘APIè¯·æ±‚çš„ä¸Šé™

# é—®é¢˜æ¸…å• (ä¿æŒä¸å˜)
QUESTIONS_DATA = """
1.1.1 ç›²é“ç –ä¹‹é—´æ˜¯å¦å­˜åœ¨æ˜æ˜¾çš„è£‚ç¼æˆ–è¿‡å®½çš„ç¼éš™ï¼Ÿ
1.1.2 ç›²é“ä¸ç›¸é‚»è·¯é¢ä¹‹é—´æ˜¯å¦å­˜åœ¨é«˜åº¦å·®ï¼Ÿ
1.1.3 ç›²é“çš„ä¸åŒéƒ¨åˆ†ä¹‹é—´æ˜¯å¦å­˜åœ¨è¾ƒå¤§çš„é¢œè‰²å·®å¼‚ï¼Ÿ
1.1.4 ç›²é“ä¸Šçš„è§¦è§‰ç‚¹æˆ–æ¡çº¹æ˜¯å¦ä¸¥é‡ç£¨æŸæˆ–ç¼ºå¤±ï¼Ÿ
1.1.5 å¯¼å‘å‹ç›²é“æ˜¯å¦ç›´æ¥å¼•å¯¼è‡³æ¥¼æ¢¯ã€æ …æ æˆ–å…¶ä»–éšœç¢ç‰©ï¼Ÿ
1.1.6 ç›²é“çš„è¿ç»­æ€§æ˜¯å¦è¢«æ£€æŸ¥äº•ç›–æˆ–ç®¡é“å‡ºå£æ‰“æ–­ï¼Ÿ
1.1.7 åœ¨éœ€è¦è®¾ç½®ç›²é“çš„ä½ç½®ï¼ˆå¦‚åœ°é“å…¥å£ã€å…¬äº¤è½¦ç«™ï¼‰æ˜¯å¦å®Œå…¨ç¼ºå¤±ç›²é“ï¼Ÿ
1.1.8 è¿™æ®µç›²é“æ˜¯å¦åŒ…å«ä¸¤ä¸ªä»¥ä¸Šè¶…è¿‡90åº¦çš„è½¬å¼¯ï¼Ÿ
1.2.1 æ˜¯å¦æœ‰è¡Œäººé•¿æ—¶é—´åœç•™åœ¨ç›²é“ä¸Šï¼Ÿ
1.2.2 æ˜¯å¦æœ‰å¿«é€’å‘˜æˆ–å¤–å–éª‘æ‰‹ä¸´æ—¶åœé åœ¨ç›²é“ä¸Šæˆ–æ—è¾¹ï¼Ÿ
1.2.3 æ˜¯å¦æœ‰æ¸…æ´è½¦è¾†æˆ–å«ç”Ÿå·¥å…·å æ®ç›²é“ï¼Ÿ
1.2.4 ç›²é“ä¸Šæ˜¯å¦æœ‰éæœºåŠ¨è½¦ï¼ˆå¦‚è‡ªè¡Œè½¦ã€ç”µåŠ¨è‡ªè¡Œè½¦ï¼‰åœæ”¾ï¼Ÿ
2.1.1 ç›²é“æ˜¯å¦è·ç¦»å¢™å£ä¸è¶³250æ¯«ç±³ï¼Ÿ
2.1.2 ç›²é“æ˜¯å¦è·ç¦»ç»¿åŒ–å¸¦æˆ–ç§æ¤åŒºä¸è¶³250æ¯«ç±³ï¼Ÿ
2.1.3 ç›²é“æ˜¯å¦è·ç¦»æ ‘å‘ä¸è¶³250æ¯«ç±³ï¼Ÿ
2.1.4 åƒåœ¾æ¡¶æ˜¯å¦æ”¾ç½®åœ¨ç›²é“ä¸¤ä¾§250æ¯«ç±³èŒƒå›´å†…ï¼Ÿ
2.1.5 æ ‡å¿—æ†ã€ç¯æŸ±æˆ–ä¿¡æ¯æŸ±æ˜¯å¦æ”¾ç½®åœ¨ç›²é“ä¸¤ä¾§250æ¯«ç±³èŒƒå›´å†…ï¼Ÿ
2.1.6 å¹¿å‘Šç®±ã€é‚®ç®±æˆ–ç”µæ°”æŸœæ˜¯å¦æ”¾ç½®åœ¨ç›²é“ä¸¤ä¾§250æ¯«ç±³èŒƒå›´å†…ï¼Ÿ
2.1.7 äº¤é€šæ†æˆ–å¯¼å‘æŸ±æ˜¯å¦ä½äºç›²é“ä¸¤ä¾§250æ¯«ç±³èŒƒå›´å†…ï¼Ÿ
2.1.8 å‘¨å›´åœ°ç –é¢œè‰²æ˜¯å¦ä¸ç›²é“è¿‡äºç›¸ä¼¼ï¼Œå¯¼è‡´éš¾ä»¥åŒºåˆ†ï¼Ÿ
2.1.9 å‘¨å›´åœ°ç –æ˜¯å¦å…·æœ‰ç›¸ä¼¼çš„è§¦è§‰çº¹ç†ï¼Œå½±å“è¾¨åˆ«ï¼Ÿ
2.1.10 ç›²é“çš„è¾¹ç¼˜æ˜¯å¦æœªæ˜ç¡®å®šä¹‰ï¼Œéš¾ä»¥é€šè¿‡è§¦æ‘¸æ£€æµ‹ï¼Ÿ
2.2.1 ç›²é“æ—è¾¹æ˜¯å¦æœ‰å»ºç­‘éšœç¢ç‰©ï¼Œä¸”æ²¡æœ‰è®¾ç½®ä¸´æ—¶å¼•å¯¼ç –ï¼Ÿ
2.2.2 æ˜¯å¦æœ‰è¡—å¤´å°è´©åœ¨ç›²é“250æ¯«ç±³èŒƒå›´å†…è®¾æ‘Šï¼Ÿ
2.2.3 æ˜¯å¦æœ‰å¿«é€’æ¶æˆ–å¹¿å‘Šæ¿ä¸´æ—¶æ”¾ç½®åœ¨ç›²é“é™„è¿‘ï¼Ÿ
2.2.4 æ˜¯å¦æœ‰å…±äº«å•è½¦åœæ”¾åœ¨ç›²é“250æ¯«ç±³èŒƒå›´å†…ï¼Ÿ
2.2.5 æ˜¯å¦æœ‰ç”µåŠ¨è‡ªè¡Œè½¦ã€è¸æ¿è½¦æˆ–å…¶ä»–éæœºåŠ¨è½¦é˜»å¡ç›²é“è¾¹ç¼˜ï¼Ÿ
3.1.1 å½“å‰äººè¡Œé“å®½åº¦æ˜¯å¦å°äº2.0ç±³ï¼Ÿ
3.1.2 äººè¡Œé“ä¸Šæ˜¯å¦æœ‰éšœç¢ç‰©ä½¿æœ‰æ•ˆé€šè¡Œå®½åº¦å°äº2.0ç±³ï¼Ÿ
3.1.3 è·¯ç¼˜çŸ³æ˜¯å¦å®Œå…¨ç¼ºå¤±ï¼Ÿ
3.1.4 è·¯ç¼˜çŸ³æ˜¯å¦è¿‡é«˜ï¼ˆå¤§äº15å˜ç±³ï¼‰ï¼Œå¯¼è‡´é€šè¡Œå›°éš¾ï¼Ÿ
3.1.5 è·¯ç¼˜çŸ³æ˜¯å¦è¿‡ä½ï¼ˆå°äº3å˜ç±³ï¼‰ï¼Œå¢åŠ è§†éšœè¡Œäººè¿›å…¥æœºåŠ¨è½¦é“çš„é£é™©ï¼Ÿ
3.1.6 äººè¡Œé“ä¸æœºåŠ¨è½¦é“ä¹‹é—´æ˜¯å¦æ²¡æœ‰æ˜ç¡®åˆ†éš”ï¼Ÿ
3.1.7 äººè¡Œé“ä¸é“è·¯æ˜¯å¦å¤„äºåŒä¸€æ°´å¹³ï¼Œæ²¡æœ‰é«˜åº¦å·®ï¼Ÿ
3.2.1 å»ºç­‘ææ–™æ˜¯å¦å †æ”¾åœ¨ç›²é“æˆ–äººè¡Œé“ä¸Šï¼Ÿ
3.2.2 æ˜¯å¦æœ‰å †ç§¯çš„ç»¿åŒ–åƒåœ¾ï¼ˆå¦‚è½å¶ã€æ ‘æï¼‰ï¼Ÿ
3.2.3 è£…ä¿®åƒåœ¾æˆ–åºŸå¼ƒå®¶å…·æ˜¯å¦å †æ”¾åœ¨ç›²é“é™„è¿‘ï¼Ÿ
3.2.4 ä¸´æ—¶å»ºç­‘å·¥åœ°æ˜¯å¦æ²¡æœ‰è®¾ç½®ç»•è¡Œé€šé“æˆ–è­¦ç¤ºæ ‡å¿—ï¼Ÿ
3.2.5 è·¯è¾¹æ‘Šè´©æ˜¯å¦å æ®äººè¡Œé“/ç›²é“ç©ºé—´ä¸”æ²¡æœ‰è®¾ç½®ç»•è¡Œå¼•å¯¼ï¼Ÿ
3.2.6 å•†åº—æ˜¯å¦å°†å•†å“æˆ–å®¶å…·æ‘†æ”¾åœ¨ç›²é“æˆ–äººè¡Œé“åŒºåŸŸï¼Ÿ
"""

def parse_questions_for_ids(questions_as_string):
    questions = []
    for line in questions_as_string.strip().split('\n'):
        if line.strip():
            parts = line.strip().split(" ", 1)
            if len(parts) == 2:
                questions.append((parts[0], parts[1]))
    return questions

def encode_image(image_path):
    try:
        with open(image_path, "rb") as image_file:
            return base64.b64encode(image_file.read()).decode('utf-8')
    except FileNotFoundError:
        print(f"é”™è¯¯: å›¾ç‰‡æ–‡ä»¶ {image_path} æœªæ‰¾åˆ°ã€‚")
        return None
    except Exception as e:
        print(f"è¯»å–æˆ–ç¼–ç å›¾ç‰‡ {image_path} æ—¶å‡ºé”™: {e}")
        return None

def format_questions(questions_as_string, num_questions_to_format=None):
    formatted_questions = []
    questions_processed_count = 0
    for line in questions_as_string.strip().split('\n'):
        if line.strip():
            if num_questions_to_format is not None and questions_processed_count >= num_questions_to_format:
                break
            formatted_questions.append(line.strip())
            questions_processed_count += 1
    return "\n".join(formatted_questions)

async def analyze_image_with_gpt4o(image_path, questions_text_block, question_ids_to_evaluate, is_test_mode, semaphore):
    base64_image = encode_image(image_path)
    if not base64_image:
        return None, image_path

    if not is_test_mode:
        pass 
    else:
        print(f"åˆ†æå›¾ç‰‡: {os.path.basename(image_path)}")
        try:
            image_size_kb = os.path.getsize(image_path) / 1024
            print(f"å›¾ç‰‡å¤§å°: {image_size_kb:.2f} KB")
        except OSError:
            pass

    system_prompt_content = """
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å›¾åƒåˆ†æåŠ©æ‰‹ï¼Œä¸“é—¨è¯„ä¼°å›¾ç‰‡ä¸­çš„ç›²é“æ˜¯å¦å­˜åœ¨é—®é¢˜ã€‚æˆ‘å°†ä¸ºä½ æä¾›ä¸€å¼ å›¾ç‰‡å’Œä¸€ä»½é—®é¢˜æ¸…å•ã€‚
è¯·ä»”ç»†åˆ†æå›¾ç‰‡ï¼Œå¹¶æ ¹æ®é—®é¢˜æ¸…å•é€é¡¹è¿›è¡Œè¯„ä¼°ã€‚

ä½ çš„ä»»åŠ¡æ˜¯ç”Ÿæˆä¸€ä¸ªJSONå¯¹è±¡ï¼Œè¯¥å¯¹è±¡åŒ…å«ä¸€ä¸ªåä¸º "evaluations" çš„æ•°ç»„ã€‚
æ•°ç»„ä¸­çš„æ¯ä¸ªå…ƒç´ éƒ½æ˜¯ä¸€ä¸ªJSONå¯¹è±¡ï¼Œä»£è¡¨å¯¹ä¸€ä¸ªé—®é¢˜çš„è¯„ä¼°ï¼ŒåŒ…å«ä»¥ä¸‹å­—æ®µï¼š
- "question_id": é—®é¢˜çš„å”¯ä¸€æ ‡è¯†ç¬¦ (ä¾‹å¦‚ "1.1.1")ã€‚
- "question_text": é—®é¢˜çš„åŸæ–‡ã€‚
- "analysis": ä½ å¯¹å›¾ç‰‡ä¸­ä¸è¯¥é—®é¢˜ç›¸å…³éƒ¨åˆ†çš„è¯¦ç»†åˆ†æå’Œè§‚å¯Ÿç»“æœã€‚
- "judgment": ä½ çš„æœ€ç»ˆåˆ¤æ–­ã€‚å¦‚æœé—®é¢˜æè¿°çš„æƒ…å†µå­˜åœ¨ï¼Œè¯·è¿”å› 1ï¼›å¦‚æœä¸å­˜åœ¨ï¼Œè¯·è¿”å› 0ã€‚å¦‚æœæ— æ³•åˆ¤æ–­ï¼Œè¯·è¿”å› -1ã€‚

é‡è¦æç¤ºï¼š
1.  è¯·ç¡®ä¿ä½ çš„å›ç­”ä¸¥æ ¼æŒ‰ç…§æŒ‡å®šçš„JSONæ ¼å¼ã€‚
2.  å¯¹äºæ¯ä¸ªé—®é¢˜ï¼Œè¯·åŠ¡å¿…åŒæ—¶æä¾› "analysis" å’Œ "judgment"ã€‚
3.  åœ¨ "analysis" ä¸­æ¸…æ™°æè¿°ä½ çš„åˆ¤æ–­ä¾æ®ã€‚
4.  é—®é¢˜æ–‡æœ¬åº”è¯¥åªåœ¨ "question_text" å­—æ®µä¸­å‡ºç°ä¸€æ¬¡ï¼Œä¸è¦åœ¨ "analysis" æˆ– "judgment" ä¸­é‡å¤é—®é¢˜ã€‚
"""
    user_prompt_text = f"""
ä»¥ä¸‹æ˜¯éœ€è¦è¯„ä¼°çš„é—®é¢˜åˆ—è¡¨ï¼š
{questions_text_block}

è¯·æ ¹æ®ä¸Šè¿°å›¾ç‰‡å’Œé—®é¢˜åˆ—è¡¨ï¼Œç”ŸæˆJSONæ ¼å¼çš„è¯„ä¼°æŠ¥å‘Šã€‚"""

    full_response_content = ""
    async with semaphore: 
        try:
            if is_test_mode:
                print("å¼€å§‹è°ƒç”¨ OpenAI API (JSONæ¨¡å¼, æµå¼è·å–å®Œæ•´å“åº”)...")
            
            start_time = pd.Timestamp.now()
            stream = await client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": system_prompt_content},
                    {"role": "user", "content": [
                        {"type": "text", "text": user_prompt_text},
                        {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{base64_image}"}}
                    ]}
                ],
                max_tokens=8192,
                temperature=0.2,
                stream=True,
                response_format={"type": "json_object"}
            )

            if is_test_mode:
                print("GPTå“åº” (æµå¼æ¥æ”¶JSON):")
                print("==================================================")
            
            async for chunk in stream:
                if chunk.choices[0].delta.content is not None:
                    content_piece = chunk.choices[0].delta.content
                    if is_test_mode:
                        print(content_piece, end='', flush=True)
                    full_response_content += content_piece
            
            if is_test_mode:
                print("\n==================================================")
                end_time = pd.Timestamp.now()
                print(f"APIè°ƒç”¨å®Œæˆï¼Œè€—æ—¶: {(end_time - start_time).total_seconds():.2f} ç§’")

        except APIConnectionError as e:
            print(f"APIè¿æ¥é”™è¯¯ (å›¾ç‰‡: {os.path.basename(image_path)}): {e}")
            return None, image_path
        except RateLimitError as e:
            print(f"APIé€Ÿç‡é™åˆ¶é”™è¯¯ (å›¾ç‰‡: {os.path.basename(image_path)}): {e}. ç­‰å¾…60ç§’åé‡è¯•...")
            await asyncio.sleep(60)
            return await analyze_image_with_gpt4o(image_path, questions_text_block, question_ids_to_evaluate, is_test_mode, semaphore) 
        except Exception as e:
            print(f"è°ƒç”¨OpenAI APIæ—¶å‘ç”Ÿé”™è¯¯ (å›¾ç‰‡: {os.path.basename(image_path)}): {e}")
            return None, image_path

    return full_response_content, image_path

def extract_answers(json_string, question_ids_expected):
    if not json_string:
        print("âš ï¸ APIå“åº”ä¸ºç©ºï¼Œæ— æ³•æå–ç­”æ¡ˆã€‚")
        return {}
    try:
        data = json.loads(json_string)
        if "evaluations" not in data or not isinstance(data["evaluations"], list):
            print("âš ï¸ APIå“åº”ä¸­æœªæ‰¾åˆ° 'evaluations' æ•°ç»„æˆ–æ ¼å¼ä¸æ­£ç¡®ã€‚")
            return {}

        answers = {}
        for evaluation in data["evaluations"]:
            q_id = evaluation.get("question_id")
            judgment = evaluation.get("judgment")
            if q_id and isinstance(judgment, int):
                answers[q_id] = judgment
            else:
                print(f"è­¦å‘Š: é—®é¢˜ {q_id} çš„è¯„ä¼°ç»“æœæ ¼å¼ä¸æ­£ç¡®æˆ–judgmentç¼ºå¤±ã€‚")
        
        final_answers = {qid: answers.get(qid, -1) for qid in question_ids_expected}
        return final_answers

    except json.JSONDecodeError:
        print(f"âš ï¸æ— æ³•è§£æAPIè¿”å›çš„JSON: {json_string[:200]}...") 
        return {qid: -1 for qid in question_ids_expected} 
    except Exception as e:
        print(f"æå–ç­”æ¡ˆæ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")
        return {qid: -1 for qid in question_ids_expected}

def save_test_mode_results(df, raw_response_content, image_name):
    os.makedirs(OUTPUT_FOLDER, exist_ok=True)
    base_filename = os.path.splitext(image_name)[0]
    excel_path = os.path.join(OUTPUT_FOLDER, f"{base_filename}_evaluation_gpt4o.xlsx")
    csv_path = os.path.join(OUTPUT_FOLDER, f"{base_filename}_evaluation_gpt4o.csv")
    raw_output_path = os.path.join(OUTPUT_FOLDER, f"{base_filename}_gpt_raw_output.txt")

    try:
        df.to_excel(excel_path, index=False)
        print(f"âœ… Excelå·²ä¿å­˜è‡³: {excel_path}")
        df.to_csv(csv_path, index=False, encoding='utf-8-sig')
        print(f"âœ… CSVå·²ä¿å­˜è‡³: {csv_path}")
    except Exception as e:
        print(f"ä¿å­˜Excel/CSVæ–‡ä»¶æ—¶å‡ºé”™: {e}")

    if raw_response_content:
        try:
            with open(raw_output_path, 'w', encoding='utf-8') as f:
                f.write(raw_response_content)
            print(f"åŸå§‹APIå“åº”å·²ä¿å­˜è‡³: {raw_output_path}")
        except Exception as e:
            print(f"ä¿å­˜åŸå§‹APIå“åº”æ—¶å‡ºé”™: {e}")

async def process_single_image_test_mode():
    print(f"ğŸ” æ­£åœ¨å¤„ç†æµ‹è¯•å›¾ç‰‡: {TEST_MODE_IMAGE_PATH}")
    questions_to_format = NUM_TEST_QUESTIONS if TEST_MODE else None
    questions_text_block = format_questions(QUESTIONS_DATA, questions_to_format)
    
    all_question_tuples = parse_questions_for_ids(QUESTIONS_DATA)
    question_ids_to_evaluate = [q_id for q_id, _ in all_question_tuples]
    if TEST_MODE and NUM_TEST_QUESTIONS is not None:
        question_ids_to_evaluate = question_ids_to_evaluate[:NUM_TEST_QUESTIONS]

    semaphore = asyncio.Semaphore(1) 
    raw_response, _ = await analyze_image_with_gpt4o(TEST_MODE_IMAGE_PATH, questions_text_block, question_ids_to_evaluate, is_test_mode=True, semaphore=semaphore)

    answers_map = extract_answers(raw_response, question_ids_to_evaluate)

    if not answers_map or all(v == -1 for v in answers_map.values()):
        print("âš ï¸ æœªèƒ½ä»APIå“åº”ä¸­æå–åˆ°æœ‰æ•ˆç­”æ¡ˆæˆ–æ‰€æœ‰ç­”æ¡ˆå‡æ— æ•ˆã€‚")
        data_for_df = {qid: [-1] for qid in question_ids_to_evaluate}
        problems_found_count = 0
    else:
        data_for_df = {qid: [answers_map.get(qid, -1)] for qid in question_ids_to_evaluate}
        problems_found_count = sum(1 for qid in question_ids_to_evaluate if answers_map.get(qid) == 1)

    main_df = pd.DataFrame(data_for_df)
    main_df.insert(0, "Image", os.path.basename(TEST_MODE_IMAGE_PATH))
    main_df["Problems_Found"] = problems_found_count
    
    save_test_mode_results(main_df, raw_response, os.path.basename(TEST_MODE_IMAGE_PATH))

    print("\næ•°æ®æ¦‚è§ˆ:")
    print(main_df.to_string())
    print(f"\nå‘ç°çš„é—®é¢˜æ•°é‡: {problems_found_count}/{len(question_ids_to_evaluate)}")

async def process_batch():
    os.makedirs(BATCH_OUTPUT_FOLDER, exist_ok=True)
    print(f"ğŸš€ æ‰¹å¤„ç†æ¨¡å¼å·²å¯ç”¨ï¼Œå°†å¤„ç† '{DATA_FOLDER}'ä¸­çš„æ‰€æœ‰å›¾ç‰‡ã€‚")
    print(f"ğŸ“‚ ç»“æœå°†ä¿å­˜åˆ°: {BATCH_OUTPUT_FOLDER}")

    image_files = [f for f in os.listdir(DATA_FOLDER) if f.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp'))]
    if not image_files:
        print(f"åœ¨ '{DATA_FOLDER}' ä¸­æœªæ‰¾åˆ°å›¾ç‰‡æ–‡ä»¶ã€‚")
        return

    print(f"å‘ç° {len(image_files)} å¼ å›¾ç‰‡å¾…å¤„ç†ã€‚")

    questions_text_block = format_questions(QUESTIONS_DATA) 
    all_question_tuples = parse_questions_for_ids(QUESTIONS_DATA)
    question_ids_expected = [q_id for q_id, _ in all_question_tuples]

    semaphore = asyncio.Semaphore(CONCURRENT_REQUEST_LIMIT)

    async def process_image_task(image_filename):
        image_path = os.path.join(DATA_FOLDER, image_filename)
        raw_response, _ = await analyze_image_with_gpt4o(image_path, questions_text_block, question_ids_expected, is_test_mode=False, semaphore=semaphore)

        if raw_response:
            raw_output_filename = f"{os.path.splitext(image_filename)[0]}_raw_response.json"
            raw_output_path = os.path.join(BATCH_OUTPUT_FOLDER, raw_output_filename)
            try:
                parsed_json = json.loads(raw_response)
                with open(raw_output_path, 'w', encoding='utf-8') as f:
                    json.dump(parsed_json, f, ensure_ascii=False, indent=2)
            except json.JSONDecodeError:
                with open(raw_output_path, 'w', encoding='utf-8') as f:
                    f.write(raw_response)
                # print(f"æç¤º: {image_filename} çš„APIå“åº”ä¸æ˜¯æœ‰æ•ˆJSONï¼Œå·²æŒ‰åŸæ ·ä¿å­˜ä¸ºæ–‡æœ¬ã€‚") 
            except Exception as e:
                print(f"ä¿å­˜ {image_filename} çš„åŸå§‹å“åº”æ—¶å‡ºé”™: {e}")

            answers_map = extract_answers(raw_response, question_ids_expected)
            
            if answers_map and not all(v == -1 for v in answers_map.values()):
                judgments_data = [answers_map.get(q_id, -1) for q_id in question_ids_expected]
                problems_found_count = sum(1 for j in judgments_data if j == 1)
                
                df_single_image = pd.DataFrame([judgments_data], columns=question_ids_expected)
                df_single_image.insert(0, "Image", image_filename)
                df_single_image["Problems_Found"] = problems_found_count

                csv_filename = f"{os.path.splitext(image_filename)[0]}_judgments.csv"
                csv_output_path = os.path.join(BATCH_OUTPUT_FOLDER, csv_filename)
                try:
                    df_single_image.to_csv(csv_output_path, index=False, encoding='utf-8-sig')
                except Exception as e:
                    print(f"ä¿å­˜ {image_filename} çš„åˆ¤æ–­ç»“æœCSVæ—¶å‡ºé”™: {e}")
                return f"{image_filename}: âœ”ï¸ ({problems_found_count} é—®é¢˜)"
            else:
                return f"{image_filename}: âš ï¸ (æå–ç­”æ¡ˆå¤±è´¥)"
        else:
            return f"{image_filename}: âŒ (APIè°ƒç”¨å¤±è´¥)"

    tasks = [process_image_task(img_file) for img_file in image_files]
    
    for future in tqdm_asyncio.as_completed(tasks, desc="å¤„ç†å›¾ç‰‡ä¸­", total=len(image_files)):
        try:
            result_message = await future
            # tqdm updates progress. Optionally print per-image result if not too verbose.
            # print(result_message) 
        except Exception as e:
            print(f"å¤„ç†æŸå›¾ç‰‡æ—¶å‘ç”Ÿæ„å¤–çš„å¼‚æ­¥é”™è¯¯: {e}")

    print("\nğŸ‰ æ‰€æœ‰å›¾ç‰‡å¤„ç†å®Œæˆã€‚")
    print(f"ğŸ“‚ è¯·æ£€æŸ¥è¾“å‡ºæ–‡ä»¶å¤¹: {BATCH_OUTPUT_FOLDER}")

if __name__ == "__main__":
    os.makedirs(OUTPUT_FOLDER, exist_ok=True)
    os.makedirs(BATCH_OUTPUT_FOLDER, exist_ok=True)

    if TEST_MODE:
        print(f"ğŸ§ª æµ‹è¯•æ¨¡å¼å·²å¯ç”¨ï¼Œå°†å¤„ç†å•å¼ å›¾ç‰‡: {TEST_MODE_IMAGE_PATH}")
        if NUM_TEST_QUESTIONS:
             print(f"   ä»…å¤„ç†å‰ {NUM_TEST_QUESTIONS} ä¸ªé—®é¢˜ã€‚")
        asyncio.run(process_single_image_test_mode())
    else:
        asyncio.run(process_batch())
